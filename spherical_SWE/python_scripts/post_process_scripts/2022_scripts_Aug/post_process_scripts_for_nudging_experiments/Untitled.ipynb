{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "879dcf77-130c-4571-ad88-cd309c3c7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import shtns\n",
    "import pylab as py\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "sys.path.append('/data/pbarpanda/python_scripts/modules/')\n",
    "import logruns as logruns\n",
    "import save_and_load_hdf5_files as h5saveload\n",
    "import eulerian_fluxes as eflux\n",
    "import netcdf_utilities as ncutil\n",
    "import os\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = 'FALSE'\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "# import shtns\n",
    "import pylab as py\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import time as ti\n",
    "\n",
    "sys.path.append('/data/pbarpanda/python_scripts/modules/')\n",
    "import logruns as logruns\n",
    "import save_and_load_hdf5_files as h5saveload\n",
    "import eulerian_fluxes as eflux\n",
    "import netcdf_utilities as ncutil\n",
    "from obspy.geodetics import kilometers2degrees\n",
    "import momentum_advection_class as momentum_advect\n",
    "from PIL import Image\n",
    "import imageio\n",
    "from IPython.display import Video\n",
    "import velocity_decomposition_rotational_divergent as velocity_decomp\n",
    "\n",
    "import os\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = 'FALSE'  ### This is because NOAA PSL lab computers are somehow not able to use \n",
    "\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", \n",
    "      [  \"darkred\", \"darkorange\", \"pink\", \"white\", \"white\",\"skyblue\", \"dodgerblue\", \"navy\"][::-1])\n",
    "\n",
    "def colorbar(fontsize=20):\n",
    "    cbar = py.colorbar()\n",
    "    for t in cbar.ax.get_yticklabels():\n",
    "         t.set_fontsize(fontsize)\n",
    "            \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "def remove_files(direc):\n",
    "    files = glob.glob(direc, recursive=True)\n",
    "\n",
    "    for f in files:\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except OSError as e:\n",
    "            print(\"Error: %s : %s\" % (f, e.strerror))\n",
    "\n",
    "            \n",
    "            \n",
    "logging_object = logruns.default_log(logfilename = 'vd', log_directory = './log/')\n",
    "\n",
    "logging_object.write('**********************************')\n",
    "\n",
    "\n",
    "\n",
    "# master_source = '/data/pbarpanda/spherical_SWE/evaluate_final_budget/Nudge_remove_U/'\n",
    "# sources       = os.listdir(master_source)\n",
    "\n",
    "# for source in [master_source+s+'/' for s in sources]:\n",
    "#     source  = source + os.listdir(source)[0]+'/'\n",
    "#     source  = source + os.listdir(source)[0]+'/'\n",
    "    \n",
    "#     if os.path.exists(source):\n",
    "        \n",
    "#         if not os.path.exists(source+'velocity_decomp.hdf5'):\n",
    "#             dicti = h5saveload.load_dict_from_hdf5(source+'spatial_data.hdf5')\n",
    "\n",
    "#             uwnd = dicti['U']\n",
    "#             vwnd = dicti['V']\n",
    "#             R    = 6371e3\n",
    "\n",
    "#             sf, vp, uD, vD, uR, vR, vrt, div = velocity_decomp.return_sf_vp_ur_ud(uwnd, vwnd, np.rad2deg(dicti['lats']), dim_order = 'tyx')\n",
    "#             fields = {'div':div*R, 'vrt':vrt*R, 'uD':uD, \\\n",
    "#                       'vD':vD, 'uR': uR, 'vR': vR,\\\n",
    "#                       'sf':sf*1e-6, 'vp':vp*1e-6, \\\n",
    "#                       'lats':dicti['lats'], 'lons':dicti['lons'],\\\n",
    "#                       'T_in_days': dicti['T_in_days']}\n",
    "\n",
    "#             h5saveload.save_dict_to_hdf5(fields, source+'velocity_decomp.hdf5')\n",
    "            \n",
    "#     else:\n",
    "#         print (source+'velocity_decomp.hdf5 \\n file already exists')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2ac3e3-92ca-4380-b240-8b1f8cca296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_source = '/data/pbarpanda/spherical_SWE/evaluate_final_budget/Nudge_remove_U/'\n",
    "sources       = os.listdir(master_source)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27f9cf2-4f06-44df-9943-78c7227d4aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dt_150_Q_forcing_10_forcing_y_0_Hmean_500_forcing_phase_speed_0_ms',\n",
       " 'dt_150_Q_forcing_10_forcing_y_0_Hmean_500_forcing_phase_speed_5_ms']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c5f8c8a-23a0-46a6-a971-7f6cded92a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/pbarpanda/spherical_SWE/evaluate_final_budget/Nudge_remove_U/dt_150_Q_forcing_10_forcing_y_0_Hmean_500_forcing_phase_speed_0_ms/U_up_days_800/H0_5000/\n",
      "/data/pbarpanda/spherical_SWE/evaluate_final_budget/Nudge_remove_U/dt_150_Q_forcing_10_forcing_y_0_Hmean_500_forcing_phase_speed_0_ms/U_up_days_800/H0_5000/\n",
      "<built-in method keys of dict object at 0x7f03d5e183c0>\n",
      "/data/pbarpanda/spherical_SWE/evaluate_final_budget/Nudge_remove_U/dt_150_Q_forcing_10_forcing_y_0_Hmean_500_forcing_phase_speed_5_ms/U_up_days_800/H0_5000/\n",
      "/data/pbarpanda/spherical_SWE/evaluate_final_budget/Nudge_remove_U/dt_150_Q_forcing_10_forcing_y_0_Hmean_500_forcing_phase_speed_5_ms/U_up_days_800/H0_5000/\n",
      "<built-in method keys of dict object at 0x7f03d5e27380>\n"
     ]
    }
   ],
   "source": [
    "for source in [master_source+s+'/' for s in sources]:\n",
    "    source  = source + os.listdir(source)[0]+'/'\n",
    "    source  = source + os.listdir(source)[0]+'/'\n",
    "    \n",
    "    if os.path.exists(source):\n",
    "       print (source)\n",
    "    \n",
    "    dicti = h5saveload.load_dict_from_hdf5(source+'spatial_data.hdf5')\n",
    "    print (source)\n",
    "    print (dicti.keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4c76d-725b-4d90-8276-63cdc7519bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
